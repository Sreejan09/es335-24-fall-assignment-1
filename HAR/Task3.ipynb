{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from langchain_groq.chat_models import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import API\n",
    "# Groq API and Models \n",
    "Groq_Token = API  # Do not share this key with anyone\n",
    "\n",
    "groq_models = {\"llama3-70b\": \"llama3-70b-8192\", \"mixtral\": \"mixtral-8x7b-32768\", \"gemma-7b\": \"gemma-7b-it\",\"llama3.1-70b\":\"llama-3.1-70b-versatile\",\"llama3-8b\":\"llama3-8b-8192\",\"llama3.1-8b\":\"llama-3.1-8b-instant\",\"gemma-9b\":\"gemma2-9b-it\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Local\\Temp\\ipykernel_176656\\3753780253.py:10: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  Feature_561_X_train = pd.read_csv(filepath, delim_whitespace=True)\n",
      "C:\\Users\\sriva\\AppData\\Local\\Temp\\ipykernel_176656\\3753780253.py:12: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  Feature_561_X_test = pd.read_csv(filepath, delim_whitespace=True)\n",
      "C:\\Users\\sriva\\AppData\\Local\\Temp\\ipykernel_176656\\3753780253.py:14: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  Feature_561_Y_train = pd.read_csv(filepath, delim_whitespace=True)\n",
      "C:\\Users\\sriva\\AppData\\Local\\Temp\\ipykernel_176656\\3753780253.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  Feature_561_Y_test = pd.read_csv(filepath, delim_whitespace=True)\n"
     ]
    }
   ],
   "source": [
    "## Here we will perform the prompting on all the data\n",
    "# Accelerometer data\n",
    "# 561 feature length dataset\n",
    "\n",
    "## Accelerometer data\n",
    "\n",
    "from dataset import Accelerometer_X_train,Accelerometer_Y_train,Accelerometer_X_test,Accelerometer_Y_test\n",
    "\n",
    "filepath = 'UCI HAR Dataset/train/X_train.txt'\n",
    "Feature_561_X_train = pd.read_csv(filepath, delim_whitespace=True)\n",
    "filepath = 'UCI HAR Dataset/test/X_test.txt'\n",
    "Feature_561_X_test = pd.read_csv(filepath, delim_whitespace=True)\n",
    "filepath = 'UCI HAR Dataset/train/y_train.txt'\n",
    "Feature_561_Y_train = pd.read_csv(filepath, delim_whitespace=True)\n",
    "filepath = 'UCI HAR Dataset/test/y_test.txt'\n",
    "Feature_561_Y_test = pd.read_csv(filepath, delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 500, 3)\n",
      "(54,)\n"
     ]
    }
   ],
   "source": [
    "print(Accelerometer_X_test.shape)\n",
    "print(Accelerometer_Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing dataset to obtain dataset in appropriate format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.293474  -0.3140436 -0.2480047]\n",
      " [ 1.258798  -0.2909032 -0.5137133]\n",
      " [ 1.258902  -0.3451832 -0.505633 ]\n",
      " ...\n",
      " [ 0.9335168  0.201874   0.3678763]\n",
      " [ 0.9347404  0.1986709  0.3690691]\n",
      " [ 0.9329036  0.1934453  0.3717121]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1080, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accelerometer_X_test_3d = Accelerometer_X_test[:,:20,:]\n",
    "Accelerometer_X_test_2d = Accelerometer_X_test_3d.reshape(-1,3)\n",
    "Accelerometer_Y_test_updated = np.repeat(Accelerometer_Y_test, 20)\n",
    "print(Accelerometer_X_test_2d)\n",
    "Accelerometer_X_test_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 ... 4 4 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1080,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Accelerometer_Y_test_updated)\n",
    "Accelerometer_Y_test_updated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {\n",
    "    1 : \"Walking\",\n",
    "    2 : \"Walking upstairs\",\n",
    "    3 : \"Walkimg downstairs\",\n",
    "    4 : \"Sitting\",\n",
    "    5 : \"Standing\",\n",
    "    6 : \"Laying\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZERO SHOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First lets define a function for zero shot prompting\n",
    "def zero_shot(X):\n",
    "    # Convert X_pca to DataFrame\n",
    "    df = pd.DataFrame(X)\n",
    "    \n",
    "    zeroshot = []\n",
    "    for index, row in df.iterrows():\n",
    "        query = f\"\"\"\n",
    "\n",
    "        I am providing you the accelerometer data as:\n",
    "\n",
    "        {row.to_dict()}\n",
    "\n",
    "        Now, based on this accelerometer data and using the dictionary, tell me the type of activity that is performed.\n",
    "\n",
    "        Here the activities can be as given in the dictionary:\n",
    "\n",
    "        {dictionary}\n",
    "\n",
    "        Don't give any explanation just print the answer i.e. the number from the dictionary to which the activity belong\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        model_name = \"gemma-7b\"  # Choose the model\n",
    "        llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "        answer = llm.invoke(query)\n",
    "        \n",
    "        zeroshot.append(answer.content)\n",
    "    print(zeroshot)\n",
    "    return zeroshot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Accelerometer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '2', '2', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '1', '2', '2', '1', '2', '2', '2', '2', '1', '1', '1', '2', '2', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1']\n"
     ]
    }
   ],
   "source": [
    "zeroshot_response = zero_shot(Accelerometer_X_test_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '2', '2', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '1', '2', '2', '1', '2', '2', '2', '2', '1', '1', '1', '2', '2', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1']\n"
     ]
    }
   ],
   "source": [
    "print(zeroshot_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 17.59%\n",
      "Precision: 0.05\n",
      "Recall: 0.18\n",
      "F1 Score: 0.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sriva\\code\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "### Quantitavely measure the accuracy of Few-Shot Learning \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "predictions = zeroshot_response\n",
    "predictions = [int(value) for value in predictions]\n",
    "true_values = Accelerometer_Y_test_updated  # Extract the single column data\n",
    "# print(\"Data type of true_values:\", type(true_values[0]))\n",
    "# print(\"Data type of predictions:\", type(predictions[0]))\n",
    "assert len(predictions) == len(true_values), \"Mismatch between predictions and true labels length\"\n",
    "\n",
    "# Calculate accuracy,precision, recall, and F1-score\n",
    "accuracy_fewshot = accuracy_score(true_values, predictions)\n",
    "precision_fewshot = precision_score(true_values, predictions, average='weighted')\n",
    "recall_fewshot = recall_score(true_values, predictions, average='weighted')\n",
    "f1_fewshot = f1_score(true_values, predictions, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy_fewshot * 100:.2f}%')\n",
    "print(f'Precision: {precision_fewshot:.2f}')\n",
    "print(f'Recall: {recall_fewshot:.2f}')\n",
    "print(f'F1 Score: {f1_fewshot:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using 561 feature length dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2.5717778e-001  -2.3285230e-002  -1.4653762e-002  -9.3840400e-001  \\\n",
      "0          0.286027        -0.013163        -0.119083        -0.975415   \n",
      "1          0.275485        -0.026050        -0.118152        -0.993819   \n",
      "2          0.270298        -0.032614        -0.117520        -0.994743   \n",
      "3          0.274833        -0.027848        -0.129527        -0.993852   \n",
      "4          0.279220        -0.018620        -0.113902        -0.994455   \n",
      "..              ...              ...              ...              ...   \n",
      "495        0.284727        -0.009262        -0.113091        -0.988795   \n",
      "496        0.275832        -0.015331        -0.105358        -0.993626   \n",
      "497        0.272315        -0.015413        -0.107014        -0.995763   \n",
      "498        0.270990        -0.013260        -0.114997        -0.987701   \n",
      "499        0.264218        -0.012400        -0.092979        -0.980132   \n",
      "\n",
      "     -9.2009078e-001  -6.6768331e-001  -9.5250112e-001  -9.2524867e-001  \\\n",
      "0          -0.967458        -0.944958        -0.986799        -0.968401   \n",
      "1          -0.969926        -0.962748        -0.994403        -0.970735   \n",
      "2          -0.973268        -0.967091        -0.995274        -0.974471   \n",
      "3          -0.967445        -0.978295        -0.994111        -0.965953   \n",
      "4          -0.970417        -0.965316        -0.994585        -0.969481   \n",
      "..               ...              ...              ...              ...   \n",
      "495        -0.953993        -0.980381        -0.989195        -0.949476   \n",
      "496        -0.970946        -0.982722        -0.993645        -0.971316   \n",
      "497        -0.987484        -0.980431        -0.996088        -0.987609   \n",
      "498        -0.926530        -0.959709        -0.991290        -0.952003   \n",
      "499        -0.903452        -0.945430        -0.981228        -0.913815   \n",
      "\n",
      "     -6.7430222e-001  -8.9408755e-001  ...  7.1645446e-002  -3.3037044e-001  \\\n",
      "0          -0.945823        -0.894088  ...       -0.401189        -0.121845   \n",
      "1          -0.963483        -0.939260  ...        0.062891        -0.190422   \n",
      "2          -0.968897        -0.938610  ...        0.116695        -0.344418   \n",
      "3          -0.977346        -0.938610  ...       -0.121711        -0.534685   \n",
      "4          -0.965897        -0.937856  ...        0.083603        -0.493517   \n",
      "..               ...              ...  ...             ...              ...   \n",
      "495        -0.979560        -0.928074  ...        0.220895        -0.210561   \n",
      "496        -0.981529        -0.941526  ...        0.285375        -0.705134   \n",
      "497        -0.977909        -0.942587  ...        0.352108        -0.610752   \n",
      "498        -0.962316        -0.936798  ...       -0.398974         0.351349   \n",
      "499        -0.941398        -0.930921  ...       -0.217674         0.031153   \n",
      "\n",
      "     -7.0597388e-001  6.4624029e-003  1.6291982e-001  -8.2588562e-001  \\\n",
      "0          -0.594944       -0.083495        0.017500        -0.434375   \n",
      "1          -0.640736       -0.034956        0.202302         0.064103   \n",
      "2          -0.736124       -0.017067        0.154438         0.340134   \n",
      "3          -0.846595       -0.002223       -0.040046         0.736715   \n",
      "4          -0.857565       -0.095681        0.048849         0.760684   \n",
      "..               ...             ...             ...              ...   \n",
      "495        -0.570845       -0.510483        0.049249        -0.011930   \n",
      "496        -0.928303       -0.115481        0.273201        -0.027442   \n",
      "497        -0.878821        0.180988       -0.101879        -0.196745   \n",
      "498        -0.034813        0.039737       -0.424547        -0.131404   \n",
      "499        -0.414054        0.074226        0.107266        -0.097186   \n",
      "\n",
      "     2.7115145e-001  -7.2000927e-001  2.7680104e-001  -5.7978304e-002  \n",
      "0          0.920593        -0.698091        0.281343        -0.083898  \n",
      "1          0.145068        -0.702771        0.280083        -0.079346  \n",
      "2          0.296407        -0.698954        0.284114        -0.077108  \n",
      "3         -0.118545        -0.692245        0.290722        -0.073857  \n",
      "4         -0.072216        -0.689816        0.294896        -0.068471  \n",
      "..              ...              ...             ...              ...  \n",
      "495       -0.030965        -0.423230       -0.301059        -0.026345  \n",
      "496        0.029881        -0.421858       -0.302179        -0.025006  \n",
      "497        0.105928        -0.420310       -0.303159        -0.025741  \n",
      "498        0.544619        -0.419642       -0.303666        -0.025384  \n",
      "499       -0.363163        -0.416088       -0.306256        -0.024349  \n",
      "\n",
      "[500 rows x 561 columns]\n",
      "(500, 561)\n",
      "Original shape: (500, 561)\n",
      "Reduced shape: (500, 48)\n"
     ]
    }
   ],
   "source": [
    "Feature_Test = Feature_561_X_test[0:500]\n",
    "print(Feature_Test)\n",
    "print(Feature_Test.shape)\n",
    "\n",
    "## As feature length dataset has 561 features which is too large lets apply PCA to get it down\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "X_pca = pca.fit_transform(Feature_Test)\n",
    "print(\"Original shape:\", Feature_Test.shape)\n",
    "print(\"Reduced shape:\", X_pca.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '4', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '4', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '4', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '4', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '4', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '4', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '4', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '4', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '4', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3']\n"
     ]
    }
   ],
   "source": [
    "zeroshot_response = zero_shot(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 11.40%\n",
      "Precision: 0.01\n",
      "Recall: 0.11\n",
      "F1 Score: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sriva\\code\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "### Quantitavely measure the accuracy of Few-Shot Learning \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "predictions = zeroshot_response\n",
    "predictions = [int(value) for value in predictions]\n",
    "true_values = Accelerometer_Y_test_updated[0:500]  # Extract the single column data\n",
    "# print(\"Data type of true_values:\", type(true_values[0]))\n",
    "# print(\"Data type of predictions:\", type(predictions[0]))\n",
    "assert len(predictions) == len(true_values), \"Mismatch between predictions and true labels length\"\n",
    "\n",
    "# Calculate accuracy,precision, recall, and F1-score\n",
    "accuracy_fewshot = accuracy_score(true_values, predictions)\n",
    "precision_fewshot = precision_score(true_values, predictions, average='weighted')\n",
    "recall_fewshot = recall_score(true_values, predictions, average='weighted')\n",
    "f1_fewshot = f1_score(true_values, predictions, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy_fewshot * 100:.2f}%')\n",
    "print(f'Precision: {precision_fewshot:.2f}')\n",
    "print(f'Recall: {recall_fewshot:.2f}')\n",
    "print(f'F1 Score: {f1_fewshot:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEW SHOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_shot(X,examples):\n",
    "    df_pca = pd.DataFrame(X)\n",
    "    fewshot = []\n",
    "    for index, row in df_pca.head(500).iterrows():\n",
    "        query = f\"\"\"\n",
    "\n",
    "        I am providing you the accelerometer data as:\n",
    "\n",
    "        {row}\n",
    "\n",
    "        Here the activities can be as given in the dictionary:\n",
    "\n",
    "        {dictionary}\n",
    "\n",
    "        In the dictionary, an integer corresponding to the activities is provided. Use those integers to denote your response.\n",
    "\n",
    "        Now, based on this accelerometer data and using the dictionary, tell me the type of activity that is performed.\n",
    "\n",
    "        Here are few examples for you\n",
    "\n",
    "        {examples}\n",
    "\n",
    "        Use these examples and the values provided to find your prediction of the activity\n",
    "\n",
    "        Don't give any explaination just print the answer, as integer\n",
    "        \"\"\"\n",
    "\n",
    "        model_name = \"gemma-7b\"  # Choose the model\n",
    "        llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "        answer = llm.invoke(query)\n",
    "\n",
    "        fewshot.append(answer.content)\n",
    "    \n",
    "    print(fewshot)\n",
    "    return fewshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "Acclerometer_examples = {\n",
    "    \"Laying\" : [0.1811413,0.7878133,0.581194],\n",
    "    \"Sitting\" : [0.9256148,0.1663663,0.3673494],\n",
    "    \"Standing\" : [1.018851,-0.123976,0.09792958],\n",
    "    \"Walking\" : [1.426164,-0.3624851,0.2789144],\n",
    "    \"Walking Downstairs\" : [0.8433239,-0.09248479,-0.05186726],\n",
    "    \"Walking Upstairs\" : [0.9599337,-0.2482484,0.02457318] \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fewshot prompting on accelerometer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '2', '2', '3', '4', '5', '4', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '4', '2', '2', '2', '4', '2', '2', '4', '2', '4', '2', '4', '2', '2', '2', '2', '4', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '4', '2', '2', '2', '2', '4', '2', '2', '4', '4', '2', '4', '2', '2', '4', '4', '2', '4', '2', '2', '2', '2', '4', '2', '2', '2', '2', '2', '4', '4', '2', '4', '2', '4', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '4', '4', '2', '2', '2', '2', '2', '2', '2', '2', '4', '4', '4', '2', '2', '4', '2', '4', '2', '2', '2', '2', '2', '4', '2', '2', '4', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '4', '2', '2', '2', '2', '2', '2', '4', '4', '2', '2', '2', '2', '2', '2', '2', '4', '2', '2', '2', '2', '2', '2', '4', '2', '2', '4', '4', '4', '2', '2', '4', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '4', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '2', '4', '4', '4', '4', '4', '2', '4', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '4', '2', '2', '2', '2', '4', '3', '2', '4', '4', '2', '2', '2', '4', '2', '4', '4', '2', '2', '2', '4', '4', '2', '2', '2', '2', '2', '2', '4', '4', '4', '4', '4', '4', '2', '4', '2', '4', '2', '2', '4', '2', '2', '2', '2', '2', '2', '2', '2', '4', '2', '2', '4', '4', '4', '2', '2', '2', '4', '4', '4', '4', '4', '4', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '4', '2', '2', '2', '4', '2', '2', '2', '2', '2', '2', '4', '2', '2', '2', '4', '2', '2', '4', '4', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '4', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '4', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2']\n"
     ]
    }
   ],
   "source": [
    "fewshot_response = few_shot(Accelerometer_X_test_2d,Acclerometer_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 19.20%\n",
      "Precision: 0.11\n",
      "Recall: 0.19\n",
      "F1 Score: 0.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sriva\\code\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "### Quantitavely measure the accuracy of Few-Shot Learning \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "predictions = fewshot_response\n",
    "predictions = [int(value) for value in predictions]\n",
    "true_values = Accelerometer_Y_test_updated[0:500]  # Extract the single column data\n",
    "# print(\"Data type of true_values:\", type(true_values[0]))\n",
    "# print(\"Data type of predictions:\", type(predictions[0]))\n",
    "# print(len(predictions))\n",
    "# print(len(true_values))\n",
    "\n",
    "assert len(predictions) == len(true_values), \"Mismatch between predictions and true labels length\"\n",
    "\n",
    "# Calculate accuracy,precision, recall, and F1-score\n",
    "accuracy_fewshot = accuracy_score(true_values, predictions)\n",
    "precision_fewshot = precision_score(true_values, predictions, average='weighted')\n",
    "recall_fewshot = recall_score(true_values, predictions, average='weighted')\n",
    "f1_fewshot = f1_score(true_values, predictions, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy_fewshot * 100:.2f}%')\n",
    "print(f'Precision: {precision_fewshot:.2f}')\n",
    "print(f'Recall: {recall_fewshot:.2f}')\n",
    "print(f'F1 Score: {f1_fewshot:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (500, 561)\n",
      "Reduced shape: (500, 47)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "Feature_Train = Feature_561_X_train[0:500]\n",
    "X_pca = pca.fit_transform(Feature_Train)\n",
    "print(\"Original shape:\", Feature_Train.shape)\n",
    "print(\"Reduced shape:\", X_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.52509953e+00  4.45750375e-03  1.71641208e+00  1.02777565e-01\n",
      " -4.93595550e-01 -4.93692491e-01 -3.58040312e-01 -2.79326666e-01\n",
      " -4.14138781e-01 -8.62714676e-01  3.28920570e-01  1.03233620e+00\n",
      "  2.50406145e-01 -3.52237581e-01 -5.84499347e-01 -5.01157446e-01\n",
      " -3.31320279e-01  5.23150691e-01  2.82992418e-01  3.47216280e-01\n",
      "  1.52066794e-01  2.62907948e-01  2.54938680e-01 -4.27275706e-01\n",
      " -3.70721992e-01  3.83185582e-01  3.62287734e-01  4.26584147e-02\n",
      " -1.32446228e-01  1.50072064e-01  5.00771286e-01 -1.05578725e-01\n",
      "  5.25610636e-01  1.91846157e-01 -5.80593825e-01 -2.57269836e-03\n",
      " -5.16932418e-02 -3.74709610e-01  5.94748418e-01  3.11882437e-01\n",
      " -2.15033679e-01 -1.23986278e-01  3.07345399e-01  1.78053231e-01\n",
      " -3.23094932e-03  2.77650340e-01 -2.15889983e-01]\n"
     ]
    }
   ],
   "source": [
    "# Print the first row of the PCA-transformed data\n",
    "print(X_pca[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature_561_examples = {\n",
    "    \"Laying\" : X_pca[51],\n",
    "    \"Sitting\" : X_pca[27],\n",
    "    \"Standing\" : X_pca[0],\n",
    "    \"Walking\" : X_pca[78],\n",
    "    \"Walking Downstairs\" : X_pca[125],\n",
    "    \"Walking Upstairs\" : X_pca[150]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2.5717778e-001  -2.3285230e-002  -1.4653762e-002  -9.3840400e-001  \\\n",
      "0          0.286027        -0.013163        -0.119083        -0.975415   \n",
      "1          0.275485        -0.026050        -0.118152        -0.993819   \n",
      "2          0.270298        -0.032614        -0.117520        -0.994743   \n",
      "3          0.274833        -0.027848        -0.129527        -0.993852   \n",
      "4          0.279220        -0.018620        -0.113902        -0.994455   \n",
      "..              ...              ...              ...              ...   \n",
      "495        0.284727        -0.009262        -0.113091        -0.988795   \n",
      "496        0.275832        -0.015331        -0.105358        -0.993626   \n",
      "497        0.272315        -0.015413        -0.107014        -0.995763   \n",
      "498        0.270990        -0.013260        -0.114997        -0.987701   \n",
      "499        0.264218        -0.012400        -0.092979        -0.980132   \n",
      "\n",
      "     -9.2009078e-001  -6.6768331e-001  -9.5250112e-001  -9.2524867e-001  \\\n",
      "0          -0.967458        -0.944958        -0.986799        -0.968401   \n",
      "1          -0.969926        -0.962748        -0.994403        -0.970735   \n",
      "2          -0.973268        -0.967091        -0.995274        -0.974471   \n",
      "3          -0.967445        -0.978295        -0.994111        -0.965953   \n",
      "4          -0.970417        -0.965316        -0.994585        -0.969481   \n",
      "..               ...              ...              ...              ...   \n",
      "495        -0.953993        -0.980381        -0.989195        -0.949476   \n",
      "496        -0.970946        -0.982722        -0.993645        -0.971316   \n",
      "497        -0.987484        -0.980431        -0.996088        -0.987609   \n",
      "498        -0.926530        -0.959709        -0.991290        -0.952003   \n",
      "499        -0.903452        -0.945430        -0.981228        -0.913815   \n",
      "\n",
      "     -6.7430222e-001  -8.9408755e-001  ...  7.1645446e-002  -3.3037044e-001  \\\n",
      "0          -0.945823        -0.894088  ...       -0.401189        -0.121845   \n",
      "1          -0.963483        -0.939260  ...        0.062891        -0.190422   \n",
      "2          -0.968897        -0.938610  ...        0.116695        -0.344418   \n",
      "3          -0.977346        -0.938610  ...       -0.121711        -0.534685   \n",
      "4          -0.965897        -0.937856  ...        0.083603        -0.493517   \n",
      "..               ...              ...  ...             ...              ...   \n",
      "495        -0.979560        -0.928074  ...        0.220895        -0.210561   \n",
      "496        -0.981529        -0.941526  ...        0.285375        -0.705134   \n",
      "497        -0.977909        -0.942587  ...        0.352108        -0.610752   \n",
      "498        -0.962316        -0.936798  ...       -0.398974         0.351349   \n",
      "499        -0.941398        -0.930921  ...       -0.217674         0.031153   \n",
      "\n",
      "     -7.0597388e-001  6.4624029e-003  1.6291982e-001  -8.2588562e-001  \\\n",
      "0          -0.594944       -0.083495        0.017500        -0.434375   \n",
      "1          -0.640736       -0.034956        0.202302         0.064103   \n",
      "2          -0.736124       -0.017067        0.154438         0.340134   \n",
      "3          -0.846595       -0.002223       -0.040046         0.736715   \n",
      "4          -0.857565       -0.095681        0.048849         0.760684   \n",
      "..               ...             ...             ...              ...   \n",
      "495        -0.570845       -0.510483        0.049249        -0.011930   \n",
      "496        -0.928303       -0.115481        0.273201        -0.027442   \n",
      "497        -0.878821        0.180988       -0.101879        -0.196745   \n",
      "498        -0.034813        0.039737       -0.424547        -0.131404   \n",
      "499        -0.414054        0.074226        0.107266        -0.097186   \n",
      "\n",
      "     2.7115145e-001  -7.2000927e-001  2.7680104e-001  -5.7978304e-002  \n",
      "0          0.920593        -0.698091        0.281343        -0.083898  \n",
      "1          0.145068        -0.702771        0.280083        -0.079346  \n",
      "2          0.296407        -0.698954        0.284114        -0.077108  \n",
      "3         -0.118545        -0.692245        0.290722        -0.073857  \n",
      "4         -0.072216        -0.689816        0.294896        -0.068471  \n",
      "..              ...              ...             ...              ...  \n",
      "495       -0.030965        -0.423230       -0.301059        -0.026345  \n",
      "496        0.029881        -0.421858       -0.302179        -0.025006  \n",
      "497        0.105928        -0.420310       -0.303159        -0.025741  \n",
      "498        0.544619        -0.419642       -0.303666        -0.025384  \n",
      "499       -0.363163        -0.416088       -0.306256        -0.024349  \n",
      "\n",
      "[500 rows x 561 columns]\n",
      "(500, 561)\n",
      "Original shape: (500, 561)\n",
      "Reduced shape: (500, 47)\n"
     ]
    }
   ],
   "source": [
    "Feature_Test = Feature_561_X_test[0:500]\n",
    "print(Feature_Test)\n",
    "print(Feature_Test.shape)\n",
    "\n",
    "## As feature length dataset has 561 features which is too large lets apply PCA to get it down\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=47)\n",
    "X_pca = pca.fit_transform(Feature_Test)\n",
    "print(\"Original shape:\", Feature_Test.shape)\n",
    "print(\"Reduced shape:\", X_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3', '3', '2', '3', '2', '3', '3', '3', '3', '2', '3', '2', '3', '2', '2', '3', '3', '3', '3', '3', '3', '3', '3', '2', '2', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '3', '2', '3', '2', '3', '3', '2', '3', '2', '3', '2', '2', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '2', '3', '2', '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '2', '3', '2', '3', '3', '3', '3', '3', '3', '2', '3', '2', '3', '3', '2', '3', '3', '3', '3', '3', '3', '2', '3', '3', '2', '3', '3', '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '2', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '3', '2', '3', '2', '3', '2', '3', '2', '3', '2', '3', '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '2', '2', '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3', '3', '2', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '2', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3']\n"
     ]
    }
   ],
   "source": [
    "fewshot_response = few_shot(X_pca,Feature_561_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 11.80%\n",
      "Precision: 0.03\n",
      "Recall: 0.12\n",
      "F1 Score: 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sriva\\code\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "### Quantitavely measure the accuracy of Few-Shot Learning \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "predictions = fewshot_response\n",
    "predictions = [int(value) for value in predictions]\n",
    "true_values = Accelerometer_Y_test_updated[0:500]  # Extract the single column data\n",
    "# print(\"Data type of true_values:\", type(true_values[0]))\n",
    "# print(\"Data type of predictions:\", type(predictions[0]))\n",
    "# print(len(predictions))\n",
    "# print(len(true_values))\n",
    "\n",
    "assert len(predictions) == len(true_values), \"Mismatch between predictions and true labels length\"\n",
    "\n",
    "# Calculate accuracy,precision, recall, and F1-score\n",
    "accuracy_fewshot = accuracy_score(true_values, predictions)\n",
    "precision_fewshot = precision_score(true_values, predictions, average='weighted')\n",
    "recall_fewshot = recall_score(true_values, predictions, average='weighted')\n",
    "f1_fewshot = f1_score(true_values, predictions, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy_fewshot * 100:.2f}%')\n",
    "print(f'Precision: {precision_fewshot:.2f}')\n",
    "print(f'Recall: {recall_fewshot:.2f}')\n",
    "print(f'F1 Score: {f1_fewshot:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2\n",
    "Quantitatively compare the accuracy of Few-Shot Learning with Decision Trees (You may use a subset of the test set if you encounter rate-limiting issues). Which method performs better? Why? [1 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans : \n",
    "\n",
    "Quantitavely as we found in case of Raw accelerometer accuracy for\n",
    "Few shot = 19.2%\n",
    "Decision Trees = 67% \n",
    "and in case of Dataset Containing 561 features accuracy for \n",
    "Few shot = \n",
    "Decision Trees = 85%\n",
    "So it is clear that Decision Trees performs better\n",
    "Now the decision tree may perform better because of these reasons as the decision trees doesn't rely on pre-trained models and they can be tailored for our specific data.Also in Few shot  pre-trained model might be over-complex leading to generalisation as the data between activities like sitting laying and standing isn't very distinctive similarly for walking , walking upstairs and walking downstairs , and it may not have been able to generalise properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3\n",
    "What are the limitations of Zero-Shot Learning and Few-Shot Learning in the context of classifying human activities based on featurized accelerometer data? [1 marks]\n",
    "\n",
    "Ans : \n",
    "### Limitations of Zero-Shot Learning (ZSL)\n",
    "\n",
    "Dependence on Semantic Descriptions:\n",
    "\n",
    "ZSL relies heavily on high-quality semantic embeddings or descriptions to relate known classes to unseen classes. If these descriptions do not accurately capture the relationships between activities, the model's performance can suffer significantly.\n",
    "\n",
    "Lack of Specificity:\n",
    "\n",
    "ZSL may struggle with highly specific or nuanced human activities that are not well-represented by the semantic embeddings. For example, subtle differences between \"Walking\" and \"Walking upstairs\" might be missed if the semantic information doesn't adequately differentiate them.\n",
    "\n",
    "Generalization Challenges:\n",
    "\n",
    "Generalizing from seen to unseen classes can be difficult when the new activities have different characteristics or distributions from the training data. ZSL might not perform well if the unseen activities are significantly different from any of the known activities.\n",
    "\n",
    "### Limitations of Few-Shot Learning (FSL)\n",
    "\n",
    "Dependency on Quality of Few Samples:\n",
    "\n",
    "The effectiveness of FSL depends heavily on the quality and representativeness of the few available samples. If these few examples are noisy, unrepresentative, or biased, the model's ability to generalize can be compromised.\n",
    "\n",
    "Data Imbalance and Overfitting:\n",
    "\n",
    "With very few examples, there is a risk of overfitting to those specific instances, particularly if there is a significant imbalance between the number of examples for different classes. This can lead to poor generalization to new, unseen examples of the activity.\n",
    "\n",
    "Complexity in Implementation:\n",
    "\n",
    "FSL often requires more complex algorithms, such as meta-learning or fine-tuning strategies, which can be more difficult to implement and may require careful tuning to work effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4\n",
    "What does the model classify when given input from an entirely new activity that it hasn't seen before? [0.5 mark]\n",
    "\n",
    "Ans :\n",
    "The model will try to classify the new input as one of the known classes it was trained on. It will assign the input to the closest class according to its learned decision boundaries, even if the input comes from an entirely different activity. This can result in incorrect or nonsensical classifications because the model doesn't recognize that the input is from a new activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5\n",
    "Test the model with random data (ensuring the data has the same dimensions and range as the previous input) and report the results. [0.5 mark]\n",
    "\n",
    "Ans: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='2' response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 193, 'total_tokens': 195, 'completion_time': 0.001142218, 'prompt_time': 0.122706666, 'queue_time': 0.0013563340000000007, 'total_time': 0.123848884}, 'model_name': 'gemma-7b-it', 'system_fingerprint': 'fp_7d8efeb0b1', 'finish_reason': 'stop', 'logprobs': None} id='run-184a2e6e-269e-4d0c-8281-61662968539e-0' usage_metadata={'input_tokens': 193, 'output_tokens': 2, 'total_tokens': 195}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_data_accelerometer = [random.random() for _ in range(3)]\n",
    "#print(random_data_accelerometer)\n",
    "\n",
    "zero_shot_query =  f\"\"\"\n",
    "\n",
    "        I am providing you the accelerometer data as:\n",
    "\n",
    "        {random_data_accelerometer}\n",
    "\n",
    "        Now, based on this accelerometer data and using the dictionary, tell me the type of activity that is performed.\n",
    "\n",
    "        Here the activities can be as given in the dictionary:\n",
    "\n",
    "        {dictionary}\n",
    "\n",
    "        Don't give any explanation just print the answer i.e. the number from the dictionary to which the activity belong nothing else\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "model_name = \"gemma-7b\"  # Choose the model\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(zero_shot_query)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='3' response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 449, 'total_tokens': 451, 'completion_time': 0.002225793, 'prompt_time': 0.303605466, 'queue_time': 0.00052629500000001, 'total_time': 0.305831259}, 'model_name': 'gemma-7b-it', 'system_fingerprint': 'fp_7d8efeb0b1', 'finish_reason': 'stop', 'logprobs': None} id='run-43b979c3-8285-4756-bc8e-20c57df3e3f8-0' usage_metadata={'input_tokens': 449, 'output_tokens': 2, 'total_tokens': 451}\n"
     ]
    }
   ],
   "source": [
    "few_shot_query = f\"\"\"\n",
    "\n",
    "        I am providing you the accelerometer data as:\n",
    "\n",
    "        {random_data_accelerometer}\n",
    "\n",
    "        Here the activities can be as given in the dictionary:\n",
    "\n",
    "        {dictionary}\n",
    "\n",
    "        In the dictionary, an integer corresponding to the activities is provided. Use those integers to denote your response.\n",
    "\n",
    "        Now, based on this accelerometer data and using the dictionary, tell me the type of activity that is performed.\n",
    "\n",
    "        Here are few examples for you\n",
    "\n",
    "        {Acclerometer_examples}\n",
    "\n",
    "        Use these examples and the values provided to find your prediction of the activity\n",
    "\n",
    "        Don't give any explaination just print the answer, as integer\n",
    "        \"\"\"\n",
    "\n",
    "model_name = \"gemma-7b\"  # Choose the model\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(few_shot_query)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
